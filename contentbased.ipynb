{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ0o0jsnRoDc",
        "outputId": "e4cb83c1-f40a-4219-e161-05db0bb3082b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2hhtEVEerF8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 데이터 불러오기\n",
        "poster = pd.read_csv('/content/drive/MyDrive/기학팀플/포스터/poster_with_cluster.csv')\n",
        "data = pd.read_csv('/content/drive/MyDrive/기학팀플/movie.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp4GunQCRqfZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# poster와 data를 movie_title을 기준으로 병합\n",
        "data = data.merge(poster[['movie_title', 'cluster']], on='movie_title', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1CHEgI9Rjg4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 필요한 열 정의\n",
        "essential_cols = ['critic_name', 'movie_id', 'movie_title', 'review_score_cleaned', 'runtime', 'audience_rating',\n",
        "                  'tomatometer_rating', 'predicted_emotion', 'movie_info_keyword', 'audience_status_Spilled',\n",
        "                  'audience_status_Upright', 'cluster'] + [col for col in data.columns if col.startswith('genre_')]\n",
        "data = data[essential_cols]\n",
        "\n",
        "# 결측값 처리: loc 사용\n",
        "data.loc[:, 'review_score_cleaned'] = data['review_score_cleaned'].fillna(data['review_score_cleaned'].mean())\n",
        "data.loc[:, 'runtime'] = data['runtime'].fillna(data['runtime'].mean())\n",
        "data.loc[:, 'audience_rating'] = data['audience_rating'].fillna(data['audience_rating'].mean())\n",
        "data = data.dropna().reset_index(drop=True)  # 결측값 제거 후 인덱스 리셋\n",
        "\n",
        "# predicted_emotion에 Label Encoding 적용\n",
        "le = LabelEncoder()\n",
        "data['predicted_emotion'] = le.fit_transform(data['predicted_emotion'])\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf = TfidfVectorizer(max_features=200)\n",
        "tfidf_matrix = tfidf.fit_transform(data['movie_info_keyword'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# TF-IDF 결과와 기존 데이터 결합\n",
        "data = pd.concat([data.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n",
        "data = data.drop(columns=['movie_info_keyword']).reset_index(drop=True)  # 필요 없는 열 제거\n",
        "\n",
        "# 콘텐츠 데이터 정의\n",
        "numeric_cols = data.select_dtypes(include=[np.number]).columns  # 숫자형 열만 선택\n",
        "content_data = data[numeric_cols].copy()  # 숫자형 데이터만 포함\n",
        "content_data['movie_id'] = data['movie_id']\n",
        "content_data['critic_name'] = data['critic_name']\n",
        "content_data['movie_title'] = data['movie_title']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJDFCVXfVKwZ",
        "outputId": "3a7503ae-09b4-4165-c221-4264490623c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Content Data Shape: (675698, 81)\n",
            "After Dropping Duplicates: (675295, 81)\n",
            "Content Features Shape: (675295, 78)\n",
            "Movie Features Shape: (1, 78)\n",
            "Content Scores Shape: (675295,)\n",
            "\n",
            "Movies similar to 'Inception':\n",
            "                    movie_title  content_score\n",
            "637832           V for Vendetta       0.999943\n",
            "653514  What Happened to Monday       0.999935\n",
            "91794            Arabian Nights       0.999933\n",
            "330753       Kong: Skull Island       0.999930\n",
            "620859     The Towering Inferno       0.999925\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "def content_based_recommend_by_movie(movie_title, content_data, n_recommendations=5):\n",
        "    # 데이터 크기 확인\n",
        "    print(f\"Initial Content Data Shape: {content_data.shape}\")\n",
        "\n",
        "    # 중복 제거\n",
        "    content_data = content_data.drop_duplicates().reset_index(drop=True)\n",
        "    print(f\"After Dropping Duplicates: {content_data.shape}\")\n",
        "\n",
        "    # 영화 데이터 추출 (중복 제거)\n",
        "    movie_data = content_data[content_data['movie_title'] == movie_title].drop_duplicates(subset=['movie_title'])\n",
        "    if movie_data.empty:\n",
        "        raise ValueError(f\"Movie '{movie_title}' not found in content_data.\")\n",
        "\n",
        "    # 영화 특징 벡터 추출\n",
        "    movie_features = movie_data.drop(columns=['critic_name', 'movie_id', 'movie_title']).values\n",
        "    if movie_features.shape[0] != 1:\n",
        "        raise ValueError(f\"Expected a single movie feature vector for '{movie_title}', got {movie_features.shape[0]} rows.\")\n",
        "\n",
        "    content_features = content_data.drop(columns=['critic_name', 'movie_id', 'movie_title']).values\n",
        "\n",
        "    # 데이터 크기 확인\n",
        "    print(f\"Content Features Shape: {content_features.shape}\")\n",
        "    print(f\"Movie Features Shape: {movie_features.shape}\")\n",
        "\n",
        "    # 콘텐츠 유사도 계산\n",
        "    content_scores = cosine_similarity(content_features, movie_features).ravel()\n",
        "    print(f\"Content Scores Shape: {content_scores.shape}\")\n",
        "\n",
        "    # 길이 확인\n",
        "    if len(content_scores) != len(content_data):\n",
        "        raise ValueError(\"Content scores 길이가 content_data와 일치하지 않습니다.\")\n",
        "\n",
        "    # 추천 영화 데이터프레임 생성\n",
        "    content_recommendations = pd.DataFrame({\n",
        "        'movie_id': content_data['movie_id'].values,\n",
        "        'content_score': content_scores,\n",
        "        'movie_title': content_data['movie_title'].values\n",
        "    })\n",
        "\n",
        "    # 입력 영화 제외\n",
        "    content_recommendations = content_recommendations[content_recommendations['movie_title'] != movie_title]\n",
        "\n",
        "    # 데이터 크기 확인 (중복 제거)\n",
        "    content_recommendations = content_recommendations.drop_duplicates(subset=['movie_id'])\n",
        "\n",
        "    # 상위 N개 추천 반환\n",
        "    return content_recommendations.sort_values(by='content_score', ascending=False).head(n_recommendations)\n",
        "\n",
        "\n",
        "# 영화 제목으로 추천 실행\n",
        "movie_title = \"Inception\"\n",
        "recommendations = content_based_recommend_by_movie(movie_title, content_data, n_recommendations=5)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"\\nMovies similar to '{movie_title}':\")\n",
        "print(recommendations[['movie_title', 'content_score']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCGWuldCm3mT"
      },
      "outputs": [],
      "source": [
        "def content_based_recommend_by_movie(movie_title, content_data, n_recommendations=5, debug=False):\n",
        "    if debug:\n",
        "        print(f\"Initial Content Data Shape: {content_data.shape}\")\n",
        "\n",
        "    # 중복 제거\n",
        "    content_data = content_data.drop_duplicates().reset_index(drop=True)\n",
        "    if debug:\n",
        "        print(f\"After Dropping Duplicates: {content_data.shape}\")\n",
        "\n",
        "    # 영화 데이터 추출 (중복 제거)\n",
        "    movie_data = content_data[content_data['movie_title'] == movie_title].drop_duplicates(subset=['movie_title'])\n",
        "    if movie_data.empty:\n",
        "        raise ValueError(f\"Movie '{movie_title}' not found in content_data.\")\n",
        "\n",
        "    # 영화 특징 벡터 추출\n",
        "    movie_features = movie_data.drop(columns=['critic_name', 'movie_id', 'movie_title']).values\n",
        "    if movie_features.shape[0] != 1:\n",
        "        raise ValueError(f\"Expected a single movie feature vector for '{movie_title}', got {movie_features.shape[0]} rows.\")\n",
        "\n",
        "    content_features = content_data.drop(columns=['critic_name', 'movie_id', 'movie_title']).values\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Content Features Shape: {content_features.shape}\")\n",
        "        print(f\"Movie Features Shape: {movie_features.shape}\")\n",
        "\n",
        "    # 콘텐츠 유사도 계산\n",
        "    content_scores = cosine_similarity(content_features, movie_features).ravel()\n",
        "    if debug:\n",
        "        print(f\"Content Scores Shape: {content_scores.shape}\")\n",
        "\n",
        "    # 추천 영화 데이터프레임 생성\n",
        "    content_recommendations = pd.DataFrame({\n",
        "        'movie_id': content_data['movie_id'].values,\n",
        "        'content_score': content_scores,\n",
        "        'movie_title': content_data['movie_title'].values\n",
        "    })\n",
        "\n",
        "    # 입력 영화 제외 및 중복 제거\n",
        "    content_recommendations = content_recommendations[content_recommendations['movie_title'] != movie_title]\n",
        "    content_recommendations = content_recommendations.drop_duplicates(subset=['movie_id'])\n",
        "\n",
        "    return content_recommendations.sort_values(by='content_score', ascending=False).head(n_recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VywUi8Kqm6mZ"
      },
      "outputs": [],
      "source": [
        "def evaluate_content_based_by_movie(test_data, content_data, n_recommendations=5, threshold=0.05):\n",
        "    all_true = []\n",
        "    all_predicted = []\n",
        "\n",
        "    for movie_title in tqdm(test_data['movie_title'].unique(), desc=\"Evaluating\", leave=True):\n",
        "        movie_actual = test_data[test_data['movie_title'] == movie_title][['movie_id', 'review_score_cleaned']].set_index('movie_id')\n",
        "        if movie_actual.empty:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            recommendations = content_based_recommend_by_movie(movie_title, content_data, n_recommendations=n_recommendations)\n",
        "            recommendations = recommendations.set_index('movie_id')['content_score']\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        predicted_ratings = recommendations.reindex(movie_actual.index).fillna(0)\n",
        "        all_true.extend(movie_actual['review_score_cleaned'])\n",
        "        all_predicted.extend(predicted_ratings)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(all_true, all_predicted))\n",
        "    mae = mean_absolute_error(all_true, all_predicted)\n",
        "    precision = precision_score(np.array(all_true) > threshold, np.array(all_predicted) > threshold, average='macro', zero_division=1)\n",
        "    recall = recall_score(np.array(all_true) > threshold, np.array(all_predicted) > threshold, average='macro', zero_division=1)\n",
        "    f1 = f1_score(np.array(all_true) > threshold, np.array(all_predicted) > threshold, average='macro', zero_division=1)\n",
        "\n",
        "    return {'RMSE': rmse, 'MAE': mae, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdg06opVSkj7",
        "outputId": "a3d167bc-03c3-451a-8e21-8a2b9c6699af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  13%|█▎        | 1812/14488 [1:30:01<10:03:36,  2.86s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "# 평가 실행\n",
        "metrics = evaluate_content_based_by_movie(test, content_data, n_recommendations=5, threshold=0.05)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"\\nContent-Based Recommendation System Metrics:\")\n",
        "print(metrics)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}