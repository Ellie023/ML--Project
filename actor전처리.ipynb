{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 파일 경로: Colab에 업로드한 파일 이름으로 지정\n",
        "file_path = '/content/filtered_df_plus_info.csv'\n",
        "\n",
        "# CSV 파일 읽기\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 확인\n",
        "print(\"데이터 샘플:\")\n",
        "print(data.head())\n",
        "print(\"\\n데이터 정보:\")\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "MVXmgx_6RPMY",
        "outputId": "91fdcf3f-48b7-4701-cb51-b212febe76e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/filtered_df_plus_info.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c875508da241>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# CSV 파일 읽기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 데이터 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/filtered_df_plus_info.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 불러오기\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로 설정\n",
        "file_path = \"/content/filtered_df_plus_info.csv\"\n",
        "\n",
        "# 데이터프레임 로드\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 열 이름 출력\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "SFjZ4l-hUDS3",
        "outputId": "7643caf4-1c8c-4f2a-b4c7-6b801205c606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/filtered_df_plus_info.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b9f0871fe65b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 데이터프레임 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 열 이름 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/filtered_df_plus_info.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 결측값 확인\n",
        "print(\"결측값 수:\", df['critic_name'].isna().sum())\n",
        "\n",
        "# 2. 결측값 처리\n",
        "df['critic_name'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# 3. 중복값 확인\n",
        "print(\"고유 비평가 수:\", df['critic_name'].nunique())\n",
        "\n",
        "# 4. 각 비평가가 작성한 리뷰 수 확인\n",
        "critic_review_counts = df['critic_name'].value_counts()\n",
        "print(critic_review_counts.head(10))  # 상위 10명 비평가\n"
      ],
      "metadata": {
        "id": "4fAxQRA-VJ3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'top_critic' 열 분석\n",
        "top_critic_counts = df['top_critic'].value_counts()\n",
        "print(\"top_critic 분포:\\n\", top_critic_counts)\n",
        "\n",
        "# 비율 확인\n",
        "top_critic_ratio = df['top_critic'].value_counts(normalize=True) * 100\n",
        "print(\"\\n각 값의 비율 (%):\\n\", top_critic_ratio)\n"
      ],
      "metadata": {
        "id": "nv2cYZhuVjl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# review_type 분포 확인\n",
        "review_type_counts = df['review_type'].value_counts()\n",
        "review_type_proportion = df['review_type'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"review_type 분포:\\n\", review_type_counts)\n",
        "print(\"\\n각 값의 비율 (%):\\n\", review_type_proportion)\n"
      ],
      "metadata": {
        "id": "FLQlKX4tVxq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# review_content 컬럼의 데이터 샘플 확인\n",
        "print(df['review_content'].head(10))\n",
        "\n",
        "# 결측값 확인\n",
        "missing_review_content = df['review_content'].isnull().sum()\n",
        "print(f\"결측값 수: {missing_review_content}\")\n"
      ],
      "metadata": {
        "id": "smq_nb34V8OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 고유 영화 제목 수 확인\n",
        "unique_movies = df['movie_title'].nunique()\n",
        "\n",
        "# 결측값 확인\n",
        "missing_values = df['movie_title'].isnull().sum()\n",
        "\n",
        "# 가장 많이 언급된 영화 제목 상위 10개\n",
        "top_movies = df['movie_title'].value_counts().head(10)\n",
        "\n",
        "print(f\"고유 영화 제목 수: {unique_movies}\")\n",
        "print(f\"결측값 수: {missing_values}\")\n",
        "print(\"가장 많이 언급된 영화 제목 상위 10개:\")\n",
        "print(top_movies)\n"
      ],
      "metadata": {
        "id": "_fa8b4uoXCBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# authors 컬럼 분석\n",
        "authors_summary = {\n",
        "    \"결측값 수\": df['authors'].isna().sum(),\n",
        "    \"고유 저자 수\": df['authors'].nunique(),\n",
        "    \"가장 많이 언급된 저자 상위 10개\": df['authors'].value_counts().head(10)\n",
        "}\n",
        "authors_summary\n"
      ],
      "metadata": {
        "id": "FOoeOIjjXj2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값 수 확인\n",
        "missing_actors = df['actors'].isna().sum()\n",
        "\n",
        "# 고유 값 수 확인\n",
        "unique_actors = df['actors'].nunique()\n",
        "\n",
        "# 가장 많이 언급된 출연진 상위 10개\n",
        "top_actors = df['actors'].value_counts().head(10)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"결측값 수: {missing_actors}\")\n",
        "print(f\"고유 출연진 수: {unique_actors}\")\n",
        "print(\"가장 많이 언급된 출연진 상위 10개:\")\n",
        "print(top_actors)\n"
      ],
      "metadata": {
        "id": "riIy9lF2aGc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j2kYkwHBbjs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 결측값 처리\n",
        "df['actors'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# 2. 배우 이름 분리 및 리스트화\n",
        "movie_actor_mapping = {}\n",
        "for idx, row in df.iterrows():\n",
        "    actors = row['actors'].split(', ') if row['actors'] != 'Unknown' else ['Unknown']\n",
        "    movie_actor_mapping[row['movie_title']] = actors\n",
        "\n",
        "# 3. 고유 배우 리스트 생성\n",
        "unique_actors = set(actor for actors in movie_actor_mapping.values() for actor in actors)\n",
        "\n",
        "# 4. 고유 배우와 ID 매핑 생성\n",
        "actor_id_mapping = {actor: idx for idx, actor in enumerate(unique_actors)}\n",
        "actor_id_map = {v: k for k, v in actor_id_mapping.items()}  # 역매핑\n",
        "\n",
        "# 5. 영화-배우 관계를 데이터프레임으로 변환\n",
        "movie_actor_df = []\n",
        "for movie_id, (movie_title, actors) in enumerate(movie_actor_mapping.items()):\n",
        "    for actor in actors:\n",
        "        actor_id = actor_id_mapping[actor]\n",
        "        movie_actor_df.append({'movie_id': movie_id, 'actor_id': actor_id})\n",
        "\n",
        "movie_actor_df = pd.DataFrame(movie_actor_df)\n",
        "\n",
        "# 6. 검증용 코드: 상위 10개 배우 이름 확인\n",
        "sample_actor_ids = movie_actor_df['actor_id'].unique()[:10]\n",
        "for actor_id in sample_actor_ids:\n",
        "    actor_name = actor_id_map.get(actor_id, 'Unknown')\n",
        "    print(f\"Actor ID: {actor_id}, Name: {actor_name}\")\n",
        "\n",
        "# 7. 최종 데이터프레임 확인\n",
        "print(\"movie_actor_df 샘플:\")\n",
        "print(movie_actor_df.head())\n"
      ],
      "metadata": {
        "id": "CGC2-Fvhcjd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# movie_actor_df에서 특정 movie_id에 대한 actor_id 확인\n",
        "sample_movie_id = 0  # 확인할 movie_id\n",
        "actor_ids_for_movie = movie_actor_df[movie_actor_df['movie_id'] == sample_movie_id]['actor_id'].tolist()\n",
        "\n",
        "print(f\"Movie ID: {sample_movie_id}에 연결된 Actor IDs: {actor_ids_for_movie}\")\n",
        "\n",
        "# actor_id를 통해 배우 이름 역매핑 확인\n",
        "actor_names_for_movie = [actor_id_map[actor_id] for actor_id in actor_ids_for_movie]\n",
        "print(f\"Movie ID: {sample_movie_id}에 연결된 배우 이름: {actor_names_for_movie}\")\n",
        "\n",
        "# actor_id_mapping의 일부를 확인\n",
        "print(\"actor_id_mapping 샘플:\")\n",
        "for actor_id, actor_name in list(actor_id_map.items())[:10]:\n",
        "    print(f\"Actor ID: {actor_id}, Name: {actor_name}\")\n"
      ],
      "metadata": {
        "id": "havPKZVPc91v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)  # 현재 데이터프레임에 포함된 컬럼 확인\n"
      ],
      "metadata": {
        "id": "_9Q6xSw0dvwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# movie_title 기반으로 movie_id 생성\n",
        "df['movie_id'] = df['movie_title'].astype('category').cat.codes\n",
        "\n",
        "# movie_id가 잘 생성되었는지 확인\n",
        "print(df[['movie_title', 'movie_id']].drop_duplicates().head())\n"
      ],
      "metadata": {
        "id": "My7bdDJUfZT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 영화 제목의 고유 개수\n",
        "unique_movie_titles = df['movie_title'].nunique()\n",
        "\n",
        "# movie_id의 고유 개수\n",
        "unique_movie_ids = df['movie_id'].nunique()\n",
        "\n",
        "# 비교 출력\n",
        "print(f\"영화 제목의 고유 개수: {unique_movie_titles}\")\n",
        "print(f\"movie_id의 고유 개수: {unique_movie_ids}\")\n",
        "\n",
        "# 두 값이 동일한지 확인\n",
        "if unique_movie_titles == unique_movie_ids:\n",
        "    print(\"✅ 영화 제목의 고유 개수와 movie_id의 고유 개수가 일치합니다.\")\n",
        "else:\n",
        "    print(\"⚠️ 영화 제목의 고유 개수와 movie_id의 고유 개수가 일치하지 않습니다. 확인이 필요합니다!\")\n"
      ],
      "metadata": {
        "id": "N5NTqKoJf7FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# authors 결측값 처리\n",
        "df['authors'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# authors 컬럼을 쉼표(,)로 분리하여 개별 작가 리스트 생성\n",
        "df['authors_split'] = df['authors'].apply(lambda x: [author.strip() for author in x.split(',')])\n",
        "\n",
        "# 고유 작가 추출\n",
        "unique_authors = set(author for authors_list in df['authors_split'] for author in authors_list)\n",
        "\n",
        "# 고유 작가에 ID 부여\n",
        "author_id_mapping = {author: idx for idx, author in enumerate(unique_authors)}\n",
        "\n",
        "# ID -> 작가 이름 역매핑 (필요 시 사용 가능)\n",
        "author_id_map = {v: k for k, v in author_id_mapping.items()}\n",
        "\n",
        "# authors_split 컬럼을 이용해 각 영화에 대한 authors 데이터프레임 생성\n",
        "movie_author_rows = []\n",
        "for idx, row in df.iterrows():\n",
        "    movie_id = row['movie_id']\n",
        "    for author in row['authors_split']:\n",
        "        author_id = author_id_mapping[author]\n",
        "        movie_author_rows.append({'movie_id': movie_id, 'author_id': author_id})\n",
        "\n",
        "# movie-author 관계 데이터프레임 생성\n",
        "movie_author_df = pd.DataFrame(movie_author_rows)\n",
        "\n",
        "# 중복 제거\n",
        "movie_author_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# 최종 결과 확인\n",
        "print(\"전체 작가 수:\", len(unique_authors))\n",
        "print(movie_author_df.head())\n",
        "print(\"관계 데이터프레임 크기:\", movie_author_df.shape)\n"
      ],
      "metadata": {
        "id": "TKT8fCq9gpuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 데이터 저장\n",
        "# 기존의 수정된 df를 그대로 저장\n",
        "output_file_name = 'processed_movie_data.csv'\n",
        "\n",
        "# 최종 저장\n",
        "df.to_csv(output_file_name, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"최종 데이터가 {output_file_name}로 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "Ya4qoUJ7iLZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_release_date 기본 정보 확인\n",
        "try:\n",
        "    # 1. 날짜 변환\n",
        "    df['original_release_date'] = pd.to_datetime(df['original_release_date'], errors='coerce')\n",
        "\n",
        "    # 2. 변환 후 요약\n",
        "    release_date_summary = {\n",
        "        \"결측값 수\": df['original_release_date'].isna().sum(),\n",
        "        \"데이터 유형\": df['original_release_date'].dtype,\n",
        "        \"최소 날짜\": df['original_release_date'].min(),\n",
        "        \"최대 날짜\": df['original_release_date'].max(),\n",
        "    }\n",
        "\n",
        "    print(\"original_release_date 요약:\")\n",
        "    print(release_date_summary)\n",
        "\n",
        "    # 3. 유니크 값 일부 확인\n",
        "    print(\"\\noriginal_release_date 유니크 값 일부:\")\n",
        "    print(df['original_release_date'].dropna().unique()[:10])\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error during processing:\", e)\n"
      ],
      "metadata": {
        "id": "GWDsIFGejoxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값 처리: 그대로 두거나 특정 값으로 채우기\n",
        "# 여기서는 결측값을 그대로 유지\n",
        "df['original_release_date'] = df['original_release_date'].fillna(pd.NaT)\n",
        "\n",
        "# 연도 추출\n",
        "df['release_year'] = df['original_release_date'].dt.year\n",
        "\n",
        "# 연도 컬럼 확인\n",
        "print(\"release_year 일부 확인:\")\n",
        "print(df[['original_release_date', 'release_year']].dropna().head())\n"
      ],
      "metadata": {
        "id": "FGThZXSekbGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}